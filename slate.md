Slide: Monsters Under the Bed (Predictions for 2026)

ðŸŽ¤ Speaking Transition (from previous slide)

> When we look back across the incidents weâ€™ve just covered, we can see a clear direction of travel. Attackers are testing boundaries, targeting trust, exploiting relationships, and in some cases outpacing our ability to govern our own tools. If we project these trajectories forward, three threats stand out as the ones that will define 2026.




---

âœ… Prediction 1: Social Engineering will surge as attackers exploit human trust to outsmart increasingly AI-driven defense systems.

Why we predict this:

As automated detection improves, attackers will focus more on manipulating people rather than systems.

AI is making social engineering hyper-personalized, faster, and more scalable â€” as we saw in deepfake-driven incidents like Arup.

Voice clones, synthetic emails, and real-time video manipulation will drive more real-time decision hijacking.


Implication for leaders:

The next line of compromise wonâ€™t look like a hack â€” it will look like a normal instruction from a trusted person.

Executives will need to rethink what â€œproof of legitimacyâ€ looks like inside their organizations.



---

âœ… Prediction 2: Extortion attacks and ransomware will intensify, with double/triple extortion becoming the standard playbook.

Why we predict this:

Ransomware groups are evolving from disruption models to influence models that combine data theft, PR pressure, and legal threats.

Incidents like Marks & Spencer and Coinbase demonstrate that financial leverage increasingly comes from exposure, not encryption.

In 2025, fewer than 55% of victim organizations used backups to recover â€” meaning attackers now control the narrative.


Implication for leaders:

Paying a ransom may no longer be a â€œquick fix,â€ as stolen data can resurface in new extortion cycles or in regulator complaints.

Reputation defense and legal positioning will become as critical as technical recovery.



---

âœ… Prediction 3: Human oversight will become the defining element of LLM governance and responsible AI security.

Why we predict this:

Incidents like the Replit AI agent showed how autonomous systems can cause damage through misaligned logic rather than malicious actors.

In May 2025, Deloitte was investigated in Australia after AI-generated reports were allegedly submitted as part of official work for federal government assessments â€” exposing a lack of oversight and sparking public trust concerns.

As AI becomes embedded in decision-making workflows, boards and regulators will demand visibility into how and when humans override or approve AI-driven actions.


Implication for leaders:

Governance frameworks will shift from asking â€œWhat can AI do?â€ to â€œWho is accountable when AI acts incorrectly?â€

AI usage will increasingly require sign-off chains, audit trails, and what regulators are calling â€œexplainability checkpoints.â€



---

âœ… Optional Closing Thought (for delivery):

> So while the tools of defense are getting smarter, the threats are becoming more psychological, more reputational, and more deeply tied to issues of governance and trust. 2026 may not be about whether we can stop attacks â€” but whether our organizations are ready to respond when trust itself is weaponized.