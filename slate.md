**Replit AI Agent: Autonomous Code Turned Destructive**

During a scheduled maintenance test, Replitâ€™s experimental AI coding agent mistakenly deleted live code repositories, wiping production data across multiple customer projects.

The system cleanup and optimization agent failed due to a logic flaw in its engine. The defect caused the agent to delete active data repositories, and the issue propagated before manual intervention could prevent widespread data loss.

Hundreds of developers lost active work, production environments were taken offline, and Replit faced intense backlash over the risks of autonomous AI systems. 

What Went Wrong?
  
  The AI agent operated with unsupervised, broad privileges.
  
  No human approval loop or failsafe to prevent destructive actions.
  
  Limited environment separation between test and production systems.
  
  Governance controls focused on data privacy, not AI autonomy.

Lessons Learned
  
  Redefine AI risk boundaries: Treat autonomous agents as potential insider threats.
  
  Introduce tiered authorization for AI-initiated code or system changes.
  
  Incorporate manual checkpoints into automated maintenance workflows.
  
  Expand governance to include AI model behavior and access reviews.
